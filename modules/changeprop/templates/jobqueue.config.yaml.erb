spec: &spec
  x-sub-request-filters:
    - type: default
      name: http
      options:
        allow:
          - pattern: /^https?:\/\//
            forward_headers:
              user-agent: true
  title: The Change Propagation for JobQueue root
  paths:
    /{api:sys}/dedupe:
      x-modules:
        - path: src/sys/deduplicator.js
          options:
            redis_prefix: 'CPJQ'
            redis:
              host: <%= @redis_host %>
              port: 6379
              password: '<%= @redis_password %>'
    /{api:sys}/partition/mediawiki_database:
      x-modules:
        - path: src/sys/partitioner.js
          options:
            templates:
              partition_stream: 'cpjobqueue.partitioned.{{message.meta.stream}}'
            partition_key: database
            partition_default: 2
            partition_map:
              # partition 0
              loginwiki: 0
              # partition 1
              metawiki: 1
              # partition 2: default
    /{api:sys}/queue:
      x-modules:
        - path: src/sys/kafka.js
          options:
            metadata_broker_list: <%= @broker_list %>
            dc_name: default
            consumer:
              # JobQueue jobs might sent messages larget then 1 Meg,
              # so we increase the max message size in kafka and have to
              # ajust the consumers accordingly.
              fetch.message.max.bytes: 4194304
              # Silence noisy connection reaper logging
              # https://github.com/Blizzard/node-rdkafka/issues/326
              # https://github.com/edenhill/librdkafka/issues/768#issuecomment-246302856
              log.connection.close: false
            producer:
              compression.codec: snappy
              # Silence noisy connection reaper logging
              # https://github.com/Blizzard/node-rdkafka/issues/326
              # https://github.com/edenhill/librdkafka/issues/768#issuecomment-246302856
              log.connection.close: false
              # The default value is 5ms, and we want Changeprop to batch
              # more messages rather than keep sending small ones.
              linger.ms: 20
            concurrency: 10
            startup_delay: 60000
            disable_blacklist: true
            disable_ratelimit: true
            disable_delayed_execution: true
            templates:
<% @high_traffic_jobs_config.each do |topic, topic_config| -%>
              <%= topic %>:
                topic: 'mediawiki.job.<%= topic %>'
<% topic_config.each do |key, value| -%>
                <%= key %>: <%= value %>
<% end -%>
                exec:
                  method: post
                  uri: '<%= @jobrunner_host %>/rpc/RunSingleJob.php'
                  headers:
                    content-type: 'application/json'
                  body: '{{globals.message}}'
                  agentOptions:
                    keepAlive: true
<% end -%>
<% @high_traffic_high_timeout_jobs_config.each do |topic, topic_config| -%>
              <%= topic %>:
                topic: 'mediawiki.job.<%= topic %>'
<% topic_config.each do |key, value| -%>
                <%= key %>: <%= value %>
<% end -%>
                exec:
                  method: post
                  uri: '<%= @jobrunner_high_timeout_host %>/rpc/RunSingleJob.php'
                  headers:
                    content-type: 'application/json'
                  body: '{{globals.message}}'
                  agentOptions:
                    keepAlive: true
<% end -%>
<% @videoscaler_jobs_config.each do |topic, topic_config| -%>
              <%= topic %>:
                topic: 'mediawiki.job.<%= topic %>'
<% topic_config.each do |key, value| -%>
                <%= key %>: <%= value %>
<% end -%>
                exec:
                  method: post
                  uri: '<%= @videoscaler_host %>/rpc/RunSingleJob.php'
                  headers:
                    content-type: 'application/json'
                  body: '{{globals.message}}'
                  agentOptions:
                    keepAlive: true
<% end -%>
<% @partitioned_jobs_config.each do |topic, options| -%>
              <%= topic %>_partitioner:
                topic: 'mediawiki.job.<%= topic %>'
                concurrency: <%= options['partitioner_concurrency'] %>
                exec:
                  method: post
                  uri: '/sys/partition/<%= options['partitioner_kind'] %>/'
                  headers:
                    content-type: application/json
                  body: '{{globals.message}}'
              <%= topic %>:
                topic: 'cpjobqueue.partitioned.mediawiki.job.<%= topic %>'
<% options['partition'].each do |key, value| -%>
                <%= key %>: <%= value %>
<% end -%>
                exec:
                  method: post
                  uri: '<%= @jobrunner_host %>/rpc/RunSingleJob.php'
                  headers:
                    content-type: application/json
                  body: '{{globals.message}}'
                  agentOptions:
                    keepAlive: true
<% end -%>
              semantic_mediawiki_jobs:
                concurrency: <%= @semantic_mediawiki_concurrency %>
                topics:
<% @semantic_mediawiki_jobs.each do |job| -%>
                  - 'mediawiki.job.<%= job %>'
<% end -%>
                exec:
                  method: post
                  uri: '<%= @jobrunner_host %>/rpc/RunSingleJob.php'
                  headers:
                    content-type: 'application/json'
                  body: '{{globals.message}}'
                  agentOptions:
                    keepAlive: true
              # Now special rule to cover all the low-traffic jobs
              low_traffic_jobs:
                concurrency: <%= @low_traffic_concurrency %>
                topics:
                  - '/^mediawiki\.job\..*/'
                # Don't execute anything that's covered by different rules
                exclude_topics:
<% @high_traffic_jobs_config.keys.each do |job| -%>
                  - 'mediawiki.job.<%= job %>'
<% end -%>
<% @high_traffic_high_timeout_jobs_config.keys.each do |job| -%>
                  - 'mediawiki.job.<%= job %>'
<% end -%>
<% @videoscaler_jobs_config.keys.each do |job| -%>
                  - 'mediawiki.job.<%= job %>'
<% end -%>
<% @partitioned_jobs_config.keys.each do |job| -%>
                  - 'mediawiki.job.<%= job %>'
<% end -%>
<% @semantic_mediawiki_jobs.each do |job| -%>
                  - 'mediawiki.job.<%= job %>'
<% end -%>
                exec:
                  method: post
                  uri: '<%= @jobrunner_host %>/rpc/RunSingleJob.php'
                  headers:
                    content-type: 'application/json'
                  body: '{{globals.message}}'
                  agentOptions:
                    keepAlive: true

# Number of worker processes to spawn.
# Set to 0 to run everything in a single process without clustering.
# Use 'ncpu' to run as many workers as there are CPU units
num_workers: <%= @num_workers %>

# Number of workers to start in parallel after the first worker.
# The first worker is always started independently. After it has completed
# its start-up, this number controls the number of workers to start in
# parallel until `num_workers` have been started. Note that setting this
# number to a too high a value might lead to high resource consumption
# (especially of CPU) during the start-up process.
startup_concurrency: 4

# Log error messages and gracefully restart a worker if v8 reports that it
# uses more heap (note: not RSS) than this many mb.
worker_heap_limit_mb: 750

# The maximum interval in ms that can pass between two beat messages
# sent by each worker to the master before it is killed
worker_heartbeat_timeout: 15000

# Logger info
logging:
  level: warn
  streams:
    - type: stdout
      named_levels: true
  sampled_levels:
    trace/dedupe: 0.001
    # With the average job insertion rate of 1000/s this will give about 1 sample log per minute
    trace/sample: 0.00002

# Statsd metrics reporter
metrics:
  name: cpjobqueue
  host: localhost
  port: 9125
  type: statsd

services:
  - name: cpjobqueue
    # a relative path or the name of an npm package, if different from name
    module: hyperswitch
    # per-service config
    conf:
      cors: "*"
      port: 7200
      # interface: localhost # uncomment to only listen on localhost
      # URL of the outbound proxy to use (complete with protocol)
      proxy: '<%= @proxy %>'
      # the list of domains for which not to use the proxy defined above
      # no_proxy_list:
      #   - domain1.com
      #   - domain2.org
      # the list of incoming request headers that can be logged; if left empty,
      # the following headers are allowed: cache-control, content-length,
      # content-type, if-match, user-agent, x-request-id
      # log_header_whitelist:
      #   - cache-control
      #   - content-length
      #   - content-type
      #   - if-match
      #   - user-agent
      #   - x-request-id
      user_agent: ChangePropagation-JobQueue/WT
      spec: *spec

